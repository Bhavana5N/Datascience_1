{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Importing all the required libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score,max_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gplearn.genetic import SymbolicRegressor, SymbolicTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "import mlxtend\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "crossvalidation = KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "def calculate_adj_r2(r_sq, n, k):\n",
    "    adj_r = 1-((1-r_sq)*(n-1)/(n-k-1))\n",
    "    return adj_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Reading the Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_1\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAirQualityUCI_1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\envname\\lib\\site-packages\\pandas\\__init__.py:244\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseArray \u001b[38;5;28;01mas\u001b[39;00m _SparseArray\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _SparseArray\n\u001b[1;32m--> 244\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'csv'"
     ]
    }
   ],
   "source": [
    "data_1=pd.csv(\"AirQualityUCI_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Changing the Names of columns</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1.rename(index=str, columns={\"CO(GT)\":\"CO_Concentrate\",\n",
    "                              \"PT08.S1(CO)\": \"Tin_Oxide\",\n",
    "                              \"NMHC(GT)\": \"Non_Metanic_Hydrocarbons\",\n",
    "                              \"C6H6(GT)\": \"Benzene_Concentration\", \n",
    "                              \"PT08.S2(NMHC)\":\"Titania_Concentration\",\n",
    "                              \"NOx(GT)\":\"NOx\",\n",
    "                              \"PT08.S3(NOx)\":\"Tungsten_Oxide_NOx\",\n",
    "                              \"NO2(GT)\":\"NO2\",\n",
    "                              \"PT08.S4(NO2)\":\"Tungsten_Oxide_NO2\",\n",
    "                              \"PT08.S5(O3)\":\"Indium_Oxide\",\n",
    "                              \"T\":\"Temperature\",\n",
    "                              \"RH\":\"Relative_Humidity\",\n",
    "                              \"AH\":\"Absolute_Humidity\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Checking whether null values are present or not</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> There are no null values in the airquality dataset</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Checking the outliers</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> We can clearly see that the minimum value of each feature is -200. We can replace negative values in the data with zero, mean, median etc</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Replacing the negative values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing all the values less than zero with zero\n",
    "for v in data_1[data_1['CO_Concentrate']<0].index:\n",
    "    data_1.loc[v,'CO_Concentrate']=0\n",
    "for v in data_1[data_1['Tin_Oxide']<0].index:\n",
    "    data_1.loc[v,'Tin_Oxide']=0\n",
    "for v in data_1[data_1['Non_Metanic_Hydrocarbons']<0].index:\n",
    "    data_1.loc[v,'Non_Metanic_Hydrocarbons']=0\n",
    "for v in data_1[data_1['Benzene_Concentration']<0].index:\n",
    "    data_1.loc[v,'Benzene_Concentration']=0\n",
    "for v in data_1[data_1['Titania_Concentration']<0].index:\n",
    "    data_1.loc[v,'Titania_Concentration']=0\n",
    "for v in data_1[data_1['NOx']<0].index:\n",
    "    data_1.loc[v,'NOx']=0\n",
    "for v in data_1[data_1['Tungsten_Oxide_NOx']<0].index:\n",
    "    data_1.loc[v,'Tungsten_Oxide_NOx']=0\n",
    "for v in data_1[data_1['NO2']<0].index:\n",
    "    data_1.loc[v,'NO2']=0\n",
    "for v in data_1[data_1['Tungsten_Oxide_NO2']<0].index:\n",
    "    data_1.loc[v,'Tungsten_Oxide_NO2']=0\n",
    "for v in data_1[data_1['Indium_Oxide']<0].index:\n",
    "    data_1.loc[v,'Indium_Oxide']=0\n",
    "for v in data_1[data_1['Temperature']<0].index:\n",
    "    data_1.loc[v,'Temperature']=0\n",
    "for v in data_1[data_1['Relative_Humidity']<0].index:\n",
    "    data_1.loc[v,'Relative_Humidity']=0\n",
    "for v in data_1[data_1['Absolute_Humidity']<0].index:\n",
    "    data_1.loc[v,'Absolute_Humidity']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also replace negative values with mean by using the following code\n",
    "#for v in data_1[data_1['CO_Concentrate']<0].index:\n",
    "#    data_1.loc[v,'CO_Concentrate']=data_1['CO_Concentrate'].mean()\n",
    "#for v in data_1[data_1['Tin_Oxide']<0].index:\n",
    "#    data_1.loc[v,'Tin_Oxide']=data_1['Tin_Oxide'].mean()\n",
    "#for v in data_1[data_1['Non_Metanic_Hydrocarbons']<0].index:\n",
    "#    data_1.loc[v,'Non_Metanic_Hydrocarbons']=data_1['Non_Metanic_Hydrocarbons'].mean()\n",
    "#for v in data_1[data_1['Benzene_Concentration']<0].index:\n",
    "#    data_1.loc[v,'Benzene_Concentration']=data_1['Benzene_Concentration'].mean()\n",
    "#for v in data_1[data_1['Titania_Concentration']<0].index:\n",
    "#    data_1.loc[v,'Titania_Concentration']=data_1['Titania_Concentration'].mean()\n",
    "#for v in data_1[data_1['NOx']<0].index:\n",
    "#    data_1.loc[v,'NOx']=data_1['NOx'].mean()\n",
    "#for v in data_1[data_1['Tungsten_Oxide_NOx']<0].index:\n",
    "#    data_1.loc[v,'Tungsten_Oxide_NOx']=data_1['Tungsten_Oxide_NOx'].mean()\n",
    "#for v in data_1[data_1['NO2']<0].index:\n",
    "#    data_1.loc[v,'NO2']=data_1['NO2'].mean()\n",
    "#for v in data_1[data_1['Tungsten_Oxide_NO2']<0].index:\n",
    "#   data_1.loc[v,'Tungsten_Oxide_NO2']=data_1['Tungsten_Oxide_NO2'].mean()\n",
    "#for v in data_1[data_1['Indium_Oxide']<0].index:\n",
    "#    data_1.loc[v,'Indium_Oxide']=data_1['Indium_Oxide'].mean()\n",
    "#for v in data_1[data_1['Temperature']<0].index:\n",
    "#    data_1.loc[v,'Temperature']=data_1['Temperature'].mean()\n",
    "#for v in data_1[data_1['Relative_Humidity']<0].index:\n",
    "#    data_1.loc[v,'Relative_Humidity']=data_1['Relative_Humidity'].mean()\n",
    "#for v in data_1[data_1['Absolute_Humidity']<0].index:\n",
    "#    data_1.loc[v,'Absolute_Humidity']=data_1['Absolute_Humidity'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1['Date']=pd.to_datetime(data_1.Date, format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1['Month'] = data_1['Date'].dt.month\n",
    "data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Time vs NO2 plot </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,15))\n",
    "sns.barplot(x='Time',y='NO2',data=data_1, ci=False)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('NO2')\n",
    "plt.title(\"NO2 with respect to Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1=data_1.drop('Date',axis=1)\n",
    "data_1=data_1.drop('Time',axis=1)\n",
    "data_1=data_1.drop('Month',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_1.drop('NO2',axis=1)\n",
    "y=data_1['NO2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Forward Feature Selection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs = SFS(lr, \n",
    "          k_features='best', \n",
    "          forward=True, \n",
    "          verbose=2,\n",
    "          floating=False, \n",
    "          scoring='r2',\n",
    "          cv=5)\n",
    "sfs=sfs.fit(X,y)\n",
    "print(\"Selected Features :\", sfs.k_feature_names_)\n",
    "print(\"Selected Features ID :\", sfs.k_feature_idx_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Backward Feature Selection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_1 = SFS(lr, \n",
    "          k_features='best', \n",
    "          forward=False, \n",
    "          floating=False, \n",
    "          verbose=2,\n",
    "          scoring='r2',\n",
    "          cv=5)\n",
    "sfs_1=sfs_1.fit(X,y)\n",
    "print(\"Selected Features :\", sfs_1.k_feature_names_)\n",
    "print(\"Selected Features ID :\", sfs_1.k_feature_idx_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Step-wise Feature Selection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_2 = SFS(lr, \n",
    "          k_features='best', \n",
    "          forward=True, \n",
    "          floating=True, \n",
    "          scoring='r2',\n",
    "          verbose=2,\n",
    "          cv=5)\n",
    "sfs=sfs.fit(X,y)\n",
    "print(\"Selected Features :\", sfs.k_feature_names_)\n",
    "print(\"Selected Features ID :\", sfs.k_feature_idx_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a new Dataframe using the features selected</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Forward, backward and step-wise feature selections gave the same best features. So I have taken features selected by forward selection and created a new dataframe using them below</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=list(sfs.k_feature_names_)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=data_1[features]\n",
    "new_data['NO2']=data_1['NO2']\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Splitting the data into train and test</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=new_data.drop('NO2',axis=1)\n",
    "y_new=new_data['NO2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_new,y_new,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Linear Regression</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train,y_train)\n",
    "predict_lr=lr.predict(X_test)\n",
    "x=r2_score(y_test,predict_lr)\n",
    "print(\"R2\",x)\n",
    "adjusted_r2=calculate_adj_r2(x,X_test.count()[0],len(X))\n",
    "print(\"Adj R2\",adjusted_r2)\n",
    "scores=cross_val_score(lr,X_train,y_train,scoring=\"r2\",cv=crossvalidation,n_jobs=1)\n",
    "print(\"Folds:\"+str(len(scores))+\",MSE:\"+str(np.mean(np.abs(scores)))+\",STD\"+str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ridge Regression</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv=RidgeCV(alphas=np.arange(.1,1,0.01),cv=5,scoring='r2')\n",
    "model_cv.fit(X_train,y_train)\n",
    "print(\"Best Alpha\",model_cv.alpha_)\n",
    "y_pred=model_cv.predict(X_test)\n",
    "x=r2_score(y_test,y_pred)\n",
    "print(\"R2\",x)\n",
    "adjusted_r2=calculate_adj_r2(x,X_test.count()[0],len(X_new))\n",
    "print(\"Adj R2\",adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge=Ridge()\n",
    "ridge.fit(X_train,y_train)\n",
    "predict_ridge=ridge.predict(X_test)\n",
    "x=r2_score(y_test, predict_ridge)\n",
    "print(\"R2\",x)\n",
    "adjusted_r2 = calculate_adj_r2(x, X_test.count()[0],len(X))\n",
    "print(\"Adj R2\",adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lasso Regression</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso=Lasso()\n",
    "lasso.fit(X_train,y_train)\n",
    "predict_lasso=lasso.predict(X_test)\n",
    "x=r2_score(y_test, predict_lasso)\n",
    "print(\"R2\",x)\n",
    "adjusted_r2 = calculate_adj_r2(x, X_test.count()[0],len(X))\n",
    "print(\"Adj R2\",adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "model_l_cv = LassoCV(cv=5, random_state=0, max_iter=10000)\n",
    "model_l_cv.fit(X_train, y_train)\n",
    "print(model_l_cv.alpha_)\n",
    "lasso_best = Lasso(alpha=model_l_cv.alpha_)\n",
    "lasso_best.fit(X_train, y_train)\n",
    "Y_Pred=lasso_best.predict(X_test)\n",
    "\n",
    "x=r2_score(y_test, Y_Pred)\n",
    "print(\"R2\",x)\n",
    "adjusted_r2 = calculate_adj_r2(x, X_test.count()[0],len(X))\n",
    "print(\"Adj R2\",adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Quadratic Regression</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadratic=PolynomialFeatures(degree=2)\n",
    "quadratic_features=quadratic.fit_transform(X_train)\n",
    "quadratic.fit(quadratic_features,y_train)\n",
    "quad_model=LinearRegression()\n",
    "quad_model.fit(quadratic_features,y_train)\n",
    "predict_quad=quad_model.predict(quadratic.fit_transform(X_test))\n",
    "x=r2_score(y_test, predict_quad)\n",
    "print(\"R2\",x)\n",
    "adjusted_r2 = calculate_adj_r2(x, X_test.count()[0],len(X))\n",
    "print(\"Adj R2\",adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Symbolic Regression</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolic = SymbolicRegressor(population_size=5000,\n",
    "                           generations=10, stopping_criteria=0.01,\n",
    "                           p_crossover=0.7, p_subtree_mutation=0.1,\n",
    "                           p_hoist_mutation=0.05, p_point_mutation=0.1,\n",
    "                           max_samples=0.9, verbose=1,\n",
    "                           parsimony_coefficient=0.01, random_state=0)\n",
    "symbolic.fit(X_train, y_train)\n",
    "score_gp = symbolic.score(X_train, y_train)\n",
    "print(score_gp)\n",
    "Y_Pred=symbolic.predict(X_test)\n",
    "x=r2_score(y_test, Y_Pred)\n",
    "print(\"R2\",x)\n",
    "adjusted_r2 = calculate_adj_r2(x, X_test.count()[0],len(X))\n",
    "print(\"Adj R2\",adjusted_r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
