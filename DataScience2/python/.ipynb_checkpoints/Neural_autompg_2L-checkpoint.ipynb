{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c857c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings ('ignore')\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "def calculate_adj_r2(r_sq, k, n):\n",
    "\n",
    "    adj_r = 1-((1-r_sq)*(n-1)/(n-k-1))\n",
    "   \n",
    "    return adj_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e114409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LabelEncode(df_local):\n",
    "    for col in df_local.columns:\n",
    "        col_dict = {}\n",
    "        if df_local[col].dtype!='object':\n",
    "            continue\n",
    "        elif df_local[col].dtype=='object':\n",
    "            col2=df_local[col].unique()\n",
    "            z=0\n",
    "            for i in col2:\n",
    "                col_dict[i]=z\n",
    "                z+=1\n",
    "            df_local[col]=df_local[col].map(col_dict)\n",
    "        \n",
    "            \n",
    "    return df_local\n",
    "\n",
    "data=pd.read_csv(\"auto-mpg.csv\")\n",
    "data.head()\n",
    "\n",
    "print(data.columns)\n",
    "data.fillna(0)\n",
    "print(data.columns)\n",
    "df_encode = LabelEncode(data)\n",
    "df_encode.shape\n",
    "\n",
    "X = ['cylinders', 'displacement', 'horsepower', 'weight',\n",
    "        'model year', 'origin', 'car name' ]\n",
    "#X=['weight', 'model year', 'origin']\n",
    "\n",
    "Y = ['mpg']\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(df_encode[X],df_encode[Y], test_size=0.25, random_state=42, shuffle=True)\n",
    "# df_train=pd.concat([X_train, Y_train], axis=1).reindex(X_train.index)\n",
    "# df_test=pd.concat([X_test, Y_test], axis=1).reindex(X_test.index)\n",
    "# print(df_train.size)\n",
    "# print(df_test.size)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_encode[X],df_encode[Y], test_size=0.25, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c5eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale both training and testing input data\n",
    "\n",
    "X_train = preprocessing.scale(X_train)\n",
    "\n",
    "X_test = preprocessing.scale(X_test)\n",
    "\n",
    "activation_list = ['linear','relu', 'sigmoid', 'tanh', 'elu','softmax','softplus','softsign','selu','exponential']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626b8958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defines linear regression model and its structure\n",
    "r2_bar_list=[]\n",
    "r2_list = []\n",
    "for i in activation_list:\n",
    "    print(\"Activation Function:\" , i)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1,input_dim=len(X), activation=i))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mae', metrics=['mae']) \n",
    "    #model.compile(Adam(lr=0.003), 'mean_squared_error')\n",
    "\n",
    "\n",
    "    #Fits model\n",
    "    history = model.fit(X_train, Y_train, epochs = 100, validation_split = 0.1,verbose = 0)\n",
    "    history_dict=history.history\n",
    "    print(history_dict.keys())\n",
    "    #Plots model's training cost/loss and model's validation split cost/loss\n",
    "    loss_values = history_dict['loss']\n",
    "    val_loss_values=history_dict['val_loss']\n",
    "    #plt.figure()\n",
    "#     plt.plot(loss_values,label='training loss')\n",
    "#     plt.plot(val_loss_values,label='val training loss')\n",
    "#     plt.show()\n",
    "    # Runs model (the one with the activation function, although this doesn't really matter as they perform the same) \n",
    "    # with its current weights on the training and testing data\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "    epochs = range(1, len(loss_values) + 1)\n",
    "    \n",
    "    r2=r2_score(Y_test, y_test_pred)\n",
    "    r2_list.append(r2)\n",
    "    r2_bar_list.append(calculate_adj_r2(r2, len(X),len(X_test)))\n",
    "    plt.subplots(1,2,figsize=(10,5))\n",
    "    plt.subplot(121)\n",
    "    plt.title('Loss curve for activation function '+ i)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss ')\n",
    "    plt.plot(epochs, loss_values, '-', label='training loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(122)\n",
    "    plt.scatter(x=range(len(X_test)), y=Y_test)\n",
    "    plt.scatter(x=range(len(X_test)), y=y_test_pred)\n",
    "    #plt.plot(epochs, val_loss_values, ':', label='val training loss')\n",
    "    \n",
    "    \n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    # Calculates and prints r2 score of training and testing data\n",
    "    #print(\"The R2 score on the Train set is:\\t{:0.3f}\".format(r2_score(Y_train, y_train_pred)))\n",
    "    #print(\"The R2 score on the Test set is:\\t{:0.3f}\".format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92830429",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Neural Net 2 Layers\")\n",
    "for i in range(len(activation_list)):\n",
    "    print(\"R2 value for using activation function %s : %s\", activation_list[i], r2_list[i])\n",
    "    print(\"Ad R2 value for using activation function %s : %s\", activation_list[i], r2_bar_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8205c03d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f743e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc2a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02990310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91bdbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23200635",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_list = []\n",
    "r2_bar_list=[]\n",
    "r2_cv_list=[]\n",
    "col_list = [X[0]]\n",
    "r_max=0\n",
    "for i in X[1:]:\n",
    "    model_cv = Sequential()    \n",
    "    model_cv.add(Dense(13, input_dim=len(col_list), activation='relu'))\n",
    "    model_cv.add(Dense(1))\n",
    "    model_cv.compile(optimizer='adam', loss='mae', metrics=['mae']) \n",
    "    X_train = preprocessing.scale(df_encode[col_list])\n",
    "\n",
    "    history = model_cv.fit(X_train, df_encode[Y], epochs = 100, validation_split = 0.2,verbose = 0, batch_size=10)\n",
    "    history_dict=history.history\n",
    "    y_test_pred = model_cv.predict(X_train)\n",
    "    r2=r2_score(df_encode[Y], y_test_pred)\n",
    "    r2_cv_list.append(r2)\n",
    "    model = Sequential()    \n",
    "    model.add(Dense(13, input_dim=len(col_list), activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mae', metrics=['mae']) \n",
    "    history = model.fit(X_train, df_encode[Y], epochs = 100, verbose = 0, batch_size=10)\n",
    "    history_dict=history.history\n",
    "    y_test_pred = model.predict(X_train)\n",
    "    r2=r2_score(df_encode[Y], y_test_pred)\n",
    "    if r2>r_max:\n",
    "        r_max=r2\n",
    "        col_list.append(i)\n",
    "    r2_list.append(r2)\n",
    "    adjusted_r2 = calculate_adj_r2(r2, X_train.count()[0],len(col_list))\n",
    "    r2_bar_list.append(adjusted_r2)\n",
    "plt.subplots(1,2,figsize=(10,5))\n",
    "plt.suptitle(title, fontsize=20)\n",
    "plt.subplot(121)\n",
    "plt.plot( range(len(col_list)), r2_list,label=\"r2\")\n",
    "plt.plot( range(len(col_list)), adjusted_r2,label=\"r2 bar\")\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.plot( range(len(col_list)), r2_cv_list,label=\"r2 cross validation\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    \n",
    "print(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1fe38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert Neural_autompg_2L.ipynb --to=pdf --TemplateExporter.exclude_input=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
